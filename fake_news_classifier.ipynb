{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "212880f0",
   "metadata": {},
   "source": [
    "# Fake News Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "665579a0",
   "metadata": {},
   "source": [
    "The objective of this project is to build a classifier that is able to distinguish between the Fake (0) and Real(1) headline news.\n",
    "\n",
    "There are two datasets provided:\n",
    "- `training_data.csv`: Dataset provided to train and test the model.\n",
    "- `testing_data.csv`: Dataset to provide the answer of the exercise.\n",
    "\n",
    "`dataset/testing_data.csv` contains all labels set as 2. The purpose of the exercise is to replace them by 0 (fake) or 1 (real) according to the model predictions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2eb30d20",
   "metadata": {},
   "source": [
    "## 1. Environment Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "732951de",
   "metadata": {},
   "source": [
    "### 1.1. Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8ae08f7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['TF_ENABLE_ONEDNN_OPTS'] = '0'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3125f6e",
   "metadata": {},
   "source": [
    "### 1.2. Tools and Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a6f67cac",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/data/Projects/miniconda/envs/nltk2/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "2025-06-19 14:48:38.140744: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1750337318.149236   18956 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1750337318.151712   18956 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "W0000 00:00:1750337318.158377   18956 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1750337318.158387   18956 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1750337318.158388   18956 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1750337318.158389   18956 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "2025-06-19 14:48:38.160761: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import sklearn\n",
    "import xgboost as xgb\n",
    "import warnings\n",
    "from transformers import pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ce4fce6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom functions\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from helpers import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e191ed15",
   "metadata": {},
   "source": [
    "### 1.3. Data Loading and Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "83590099",
   "metadata": {},
   "outputs": [],
   "source": [
    "warnings.filterwarnings(\"ignore\")\n",
    "seed = 42"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c83f308b",
   "metadata": {},
   "source": [
    "## 2. Data Loading and Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad9a820c",
   "metadata": {},
   "source": [
    "### 2.1. Initial Data Inspection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e64e75f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>corpus</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>donald trump sends out embarrassing new year‚s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>drunk bragging trump staffer started russian c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>sheriff david clarke becomes an internet joke ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>trump is so obsessed he even has obama‚s name ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>pope francis just called out donald trump duri...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34147</th>\n",
       "      <td>1</td>\n",
       "      <td>tears in rain as thais gather for late king's ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34148</th>\n",
       "      <td>1</td>\n",
       "      <td>pyongyang university needs non-u.s. teachers a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34149</th>\n",
       "      <td>1</td>\n",
       "      <td>philippine president duterte to visit japan ah...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34150</th>\n",
       "      <td>1</td>\n",
       "      <td>japan's abe may have won election\\tbut many do...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34151</th>\n",
       "      <td>1</td>\n",
       "      <td>demoralized and divided: inside catalonia's po...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>34152 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       label                                             corpus\n",
       "0          0  donald trump sends out embarrassing new year‚s...\n",
       "1          0  drunk bragging trump staffer started russian c...\n",
       "2          0  sheriff david clarke becomes an internet joke ...\n",
       "3          0  trump is so obsessed he even has obama‚s name ...\n",
       "4          0  pope francis just called out donald trump duri...\n",
       "...      ...                                                ...\n",
       "34147      1  tears in rain as thais gather for late king's ...\n",
       "34148      1  pyongyang university needs non-u.s. teachers a...\n",
       "34149      1  philippine president duterte to visit japan ah...\n",
       "34150      1  japan's abe may have won election\\tbut many do...\n",
       "34151      1  demoralized and divided: inside catalonia's po...\n",
       "\n",
       "[34152 rows x 2 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df = pd.read_csv(\"./dataset/training_data.csv\", sep=\"\\t\", header=None)\n",
    "train_df.columns = [\"label\", \"corpus\"]\n",
    "train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8b806321",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split between X and y\n",
    "X = train_df[\"corpus\"]\n",
    "y = train_df[\"label\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6e41c7de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "How many JavaScript scripts are contained in the corpus? 0\n",
      "How many CSS scripts are contained in the corpus? 0\n",
      "How many HTML tags are contained in the corpus? 0\n"
     ]
    }
   ],
   "source": [
    "def find_all(find, text):\n",
    "    result = re.findall(find, text)\n",
    "    return result\n",
    "\n",
    "print(\"How many JavaScript scripts are contained in the corpus?\", X.apply(lambda x: len(find_all(r'<[/]?script[\\s>]{1}', x.lower()))).sum())\n",
    "print(\"How many CSS scripts are contained in the corpus?\", X.apply(lambda x: len(find_all(r'<[/]?style[\\s>]{1}', x.lower()))).sum())\n",
    "print(\"How many HTML tags are contained in the corpus?\", X.apply(lambda x: len(find_all(r'<[/a-zA-Z]{1,}[\\s>]{1}', x))).sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cd51b7c",
   "metadata": {},
   "source": [
    "**Analysis:**\n",
    "- We don't need to clean HTML, Javascript or HTML code"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "199823bf",
   "metadata": {},
   "source": [
    "###  2.2. Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bf0b82e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original: trump is so obsessed he even has obama‚s name coded into his website (images)\n",
      "Cleaned:  trump is so obsessed he even has obama name coded into his website images \n"
     ]
    }
   ],
   "source": [
    "def clean_serie(serie):\n",
    "    # Remove numbers and special numbers\n",
    "    serie = serie.replace(r\"[^a-zA-Z]\", \" \", regex=True, inplace=False)\n",
    "    # Remove single chars\n",
    "    serie = serie.replace(r'^(\\w{1}\\s)|(\\s\\w{1}\\s)|(\\s\\w{1})$', \" \", regex=True, inplace=False)\n",
    "    # Remove multiple empty spaces\n",
    "    serie = serie.replace(r\"\\s{2,}\", \" \", regex=True, inplace=False)\n",
    "    # Make all string lowercase\n",
    "    serie = serie.str.lower()\n",
    "    return serie\n",
    "\n",
    "X = clean_serie(X)\n",
    "\n",
    "checkline = 3\n",
    "print(\"Original:\", train_df[\"corpus\"][checkline])\n",
    "print(\"Cleaned: \", X[checkline])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02563bc7",
   "metadata": {},
   "source": [
    "**Analysis**:\n",
    "- We decided to format the data by:\n",
    "    - Removing special characters and numbers\n",
    "    - Remove single chars\n",
    "    - Remove multiple spaces\n",
    "    - Transform all the text to lowercase"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1459e29a",
   "metadata": {},
   "source": [
    "###  2.3. Training and Test Sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a2499d0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split Data between train and test\n",
    "X_train, X_test, y_train, y_test = sklearn.model_selection.train_test_split(X, y, test_size=.2, random_state=seed)\n",
    "\n",
    "# Prepare CountVector\n",
    "count_vector = sklearn.feature_extraction.text.CountVectorizer(ngram_range=(2,2))\n",
    "\n",
    "# Transform fit and transform data\n",
    "train_ds = count_vector.fit_transform(X_train)\n",
    "test_ds = count_vector.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f30ff250",
   "metadata": {},
   "source": [
    "## 3. Baseline Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62fa01d5",
   "metadata": {},
   "source": [
    "### 3.1. Baseline Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c2ad66de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set and fit Classifier Model\n",
    "rfc = sklearn.ensemble.RandomForestClassifier(n_estimators=200, n_jobs=-1, criterion='entropy', random_state=seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe3647ce",
   "metadata": {},
   "source": [
    "### 3.2. Training and Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "10385646",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accuracy_test</th>\n",
       "      <th>precision_test</th>\n",
       "      <th>recall_test</th>\n",
       "      <th>f1_test</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.814668</td>\n",
       "      <td>0.871804</td>\n",
       "      <td>0.722895</td>\n",
       "      <td>0.790397</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   accuracy_test  precision_test  recall_test   f1_test\n",
       "0       0.814668        0.871804     0.722895  0.790397"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Metrics Details:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.90      0.83      3529\n",
      "           1       0.87      0.72      0.79      3302\n",
      "\n",
      "    accuracy                           0.81      6831\n",
      "   macro avg       0.82      0.81      0.81      6831\n",
      "weighted avg       0.82      0.81      0.81      6831\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Fit the model\n",
    "rfc.fit(train_ds, y_train)\n",
    "\n",
    "# Get Test predictions\n",
    "predictions = rfc.predict(test_ds)\n",
    "\n",
    "result = get_classifier_metrics(y_test, predictions , sub_name=\"_test\")\n",
    "display(pd.DataFrame.from_dict(result, orient='index').T)\n",
    "\n",
    "print(\"\\nMetrics Details:\")\n",
    "print(sklearn.metrics.classification_report(y_test, predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "391c1d4b",
   "metadata": {},
   "source": [
    "## 4. Machine Learning Model Experimentation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42543a44",
   "metadata": {},
   "source": [
    "### 4.1. Models and Vectorizers Combinations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca8cafd1",
   "metadata": {},
   "source": [
    "We'll compare the next models with different classifiers to see how do they perform (on default settings) with our data.\n",
    "\n",
    "We'll focus on Accuracy and Recall since the last one is the metric we want to improve in order to avoid False Negatives (we will penalize Fake News classified as Real News)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fa40f2d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "models = [sklearn.neighbors.KNeighborsClassifier(),\n",
    "          sklearn.linear_model.LogisticRegression(random_state=seed),\n",
    "          sklearn.tree.DecisionTreeClassifier(random_state=seed),\n",
    "          sklearn.ensemble.RandomForestClassifier(random_state=seed, n_jobs=-1),\n",
    "          sklearn.ensemble.AdaBoostClassifier(random_state=seed),\n",
    "          xgb.XGBClassifier(random_state=seed),\n",
    "          sklearn.naive_bayes.BernoulliNB()]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9266163e",
   "metadata": {},
   "source": [
    "#### 4.1.1. Count Vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7c4c51b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>fit_time</th>\n",
       "      <th>vectorizer</th>\n",
       "      <th>accuracy_train</th>\n",
       "      <th>precision_train</th>\n",
       "      <th>recall_train</th>\n",
       "      <th>f1_train</th>\n",
       "      <th>accuracy_test</th>\n",
       "      <th>precision_test</th>\n",
       "      <th>recall_test</th>\n",
       "      <th>f1_test</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>0.000908</td>\n",
       "      <td>CountVectorizer</td>\n",
       "      <td>0.607298</td>\n",
       "      <td>0.955016</td>\n",
       "      <td>0.201461</td>\n",
       "      <td>0.332732</td>\n",
       "      <td>0.573854</td>\n",
       "      <td>0.896552</td>\n",
       "      <td>0.133858</td>\n",
       "      <td>0.232938</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>4.545018</td>\n",
       "      <td>CountVectorizer</td>\n",
       "      <td>0.981223</td>\n",
       "      <td>0.976199</td>\n",
       "      <td>0.985389</td>\n",
       "      <td>0.980773</td>\n",
       "      <td>0.949349</td>\n",
       "      <td>0.939619</td>\n",
       "      <td>0.956693</td>\n",
       "      <td>0.948079</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>2.364206</td>\n",
       "      <td>CountVectorizer</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.879373</td>\n",
       "      <td>0.881701</td>\n",
       "      <td>0.866747</td>\n",
       "      <td>0.874160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>1.123251</td>\n",
       "      <td>CountVectorizer</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.929732</td>\n",
       "      <td>0.938471</td>\n",
       "      <td>0.914597</td>\n",
       "      <td>0.926380</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>0.562853</td>\n",
       "      <td>CountVectorizer</td>\n",
       "      <td>0.773508</td>\n",
       "      <td>0.694566</td>\n",
       "      <td>0.953080</td>\n",
       "      <td>0.803543</td>\n",
       "      <td>0.782316</td>\n",
       "      <td>0.701086</td>\n",
       "      <td>0.958207</td>\n",
       "      <td>0.809725</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>XGBClassifier</td>\n",
       "      <td>1.214446</td>\n",
       "      <td>CountVectorizer</td>\n",
       "      <td>0.916841</td>\n",
       "      <td>0.880672</td>\n",
       "      <td>0.958804</td>\n",
       "      <td>0.918079</td>\n",
       "      <td>0.908066</td>\n",
       "      <td>0.874510</td>\n",
       "      <td>0.945488</td>\n",
       "      <td>0.908615</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>BernoulliNB</td>\n",
       "      <td>0.002997</td>\n",
       "      <td>CountVectorizer</td>\n",
       "      <td>0.952710</td>\n",
       "      <td>0.939756</td>\n",
       "      <td>0.964528</td>\n",
       "      <td>0.951981</td>\n",
       "      <td>0.944810</td>\n",
       "      <td>0.933333</td>\n",
       "      <td>0.953967</td>\n",
       "      <td>0.943538</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    model  fit_time       vectorizer  accuracy_train  \\\n",
       "0    KNeighborsClassifier  0.000908  CountVectorizer        0.607298   \n",
       "1      LogisticRegression  4.545018  CountVectorizer        0.981223   \n",
       "2  DecisionTreeClassifier  2.364206  CountVectorizer        1.000000   \n",
       "3  RandomForestClassifier  1.123251  CountVectorizer        1.000000   \n",
       "4      AdaBoostClassifier  0.562853  CountVectorizer        0.773508   \n",
       "5           XGBClassifier  1.214446  CountVectorizer        0.916841   \n",
       "6             BernoulliNB  0.002997  CountVectorizer        0.952710   \n",
       "\n",
       "   precision_train  recall_train  f1_train  accuracy_test  precision_test  \\\n",
       "0         0.955016      0.201461  0.332732       0.573854        0.896552   \n",
       "1         0.976199      0.985389  0.980773       0.949349        0.939619   \n",
       "2         1.000000      1.000000  1.000000       0.879373        0.881701   \n",
       "3         1.000000      1.000000  1.000000       0.929732        0.938471   \n",
       "4         0.694566      0.953080  0.803543       0.782316        0.701086   \n",
       "5         0.880672      0.958804  0.918079       0.908066        0.874510   \n",
       "6         0.939756      0.964528  0.951981       0.944810        0.933333   \n",
       "\n",
       "   recall_test   f1_test  \n",
       "0     0.133858  0.232938  \n",
       "1     0.956693  0.948079  \n",
       "2     0.866747  0.874160  \n",
       "3     0.914597  0.926380  \n",
       "4     0.958207  0.809725  \n",
       "5     0.945488  0.908615  \n",
       "6     0.953967  0.943538  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "vectorizers = [sklearn.feature_extraction.text.CountVectorizer()]\n",
    "results = compare_vectorizers(vectorizers, models, X_train, y_train, X_test, y_test)\n",
    "display(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "064aa43f",
   "metadata": {},
   "source": [
    "**Analysis**:\n",
    "- The 2 best behaving models for our data and CountVectorizer are:\n",
    "    - LogisticRegression (accuracy: 0.944, recall: 0.956)\n",
    "    - BernoulliNB        (accuracy: 0.937, recall: 0.944)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6256a2db",
   "metadata": {},
   "source": [
    "#### 4.1.2. TF-IDF Vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0ba69da6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>fit_time</th>\n",
       "      <th>vectorizer</th>\n",
       "      <th>accuracy_train</th>\n",
       "      <th>precision_train</th>\n",
       "      <th>recall_train</th>\n",
       "      <th>f1_train</th>\n",
       "      <th>accuracy_test</th>\n",
       "      <th>precision_test</th>\n",
       "      <th>recall_test</th>\n",
       "      <th>f1_test</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>0.000936</td>\n",
       "      <td>TfidfVectorizer</td>\n",
       "      <td>0.930383</td>\n",
       "      <td>0.919407</td>\n",
       "      <td>0.939072</td>\n",
       "      <td>0.929136</td>\n",
       "      <td>0.894305</td>\n",
       "      <td>0.875655</td>\n",
       "      <td>0.910660</td>\n",
       "      <td>0.892815</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>1.947409</td>\n",
       "      <td>TfidfVectorizer</td>\n",
       "      <td>0.961751</td>\n",
       "      <td>0.952973</td>\n",
       "      <td>0.969122</td>\n",
       "      <td>0.960980</td>\n",
       "      <td>0.944810</td>\n",
       "      <td>0.931798</td>\n",
       "      <td>0.955784</td>\n",
       "      <td>0.943639</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>2.257914</td>\n",
       "      <td>TfidfVectorizer</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.883326</td>\n",
       "      <td>0.872214</td>\n",
       "      <td>0.888855</td>\n",
       "      <td>0.880456</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>0.985260</td>\n",
       "      <td>TfidfVectorizer</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.934417</td>\n",
       "      <td>0.924450</td>\n",
       "      <td>0.941248</td>\n",
       "      <td>0.932773</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>1.547843</td>\n",
       "      <td>TfidfVectorizer</td>\n",
       "      <td>0.791442</td>\n",
       "      <td>0.715537</td>\n",
       "      <td>0.947582</td>\n",
       "      <td>0.815372</td>\n",
       "      <td>0.798565</td>\n",
       "      <td>0.719963</td>\n",
       "      <td>0.954573</td>\n",
       "      <td>0.820833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>XGBClassifier</td>\n",
       "      <td>12.197378</td>\n",
       "      <td>TfidfVectorizer</td>\n",
       "      <td>0.932470</td>\n",
       "      <td>0.903110</td>\n",
       "      <td>0.964528</td>\n",
       "      <td>0.932809</td>\n",
       "      <td>0.918021</td>\n",
       "      <td>0.886633</td>\n",
       "      <td>0.952150</td>\n",
       "      <td>0.918224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>BernoulliNB</td>\n",
       "      <td>0.003238</td>\n",
       "      <td>TfidfVectorizer</td>\n",
       "      <td>0.952710</td>\n",
       "      <td>0.939756</td>\n",
       "      <td>0.964528</td>\n",
       "      <td>0.951981</td>\n",
       "      <td>0.944810</td>\n",
       "      <td>0.933333</td>\n",
       "      <td>0.953967</td>\n",
       "      <td>0.943538</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    model   fit_time       vectorizer  accuracy_train  \\\n",
       "0    KNeighborsClassifier   0.000936  TfidfVectorizer        0.930383   \n",
       "1      LogisticRegression   1.947409  TfidfVectorizer        0.961751   \n",
       "2  DecisionTreeClassifier   2.257914  TfidfVectorizer        1.000000   \n",
       "3  RandomForestClassifier   0.985260  TfidfVectorizer        1.000000   \n",
       "4      AdaBoostClassifier   1.547843  TfidfVectorizer        0.791442   \n",
       "5           XGBClassifier  12.197378  TfidfVectorizer        0.932470   \n",
       "6             BernoulliNB   0.003238  TfidfVectorizer        0.952710   \n",
       "\n",
       "   precision_train  recall_train  f1_train  accuracy_test  precision_test  \\\n",
       "0         0.919407      0.939072  0.929136       0.894305        0.875655   \n",
       "1         0.952973      0.969122  0.960980       0.944810        0.931798   \n",
       "2         1.000000      1.000000  1.000000       0.883326        0.872214   \n",
       "3         1.000000      1.000000  1.000000       0.934417        0.924450   \n",
       "4         0.715537      0.947582  0.815372       0.798565        0.719963   \n",
       "5         0.903110      0.964528  0.932809       0.918021        0.886633   \n",
       "6         0.939756      0.964528  0.951981       0.944810        0.933333   \n",
       "\n",
       "   recall_test   f1_test  \n",
       "0     0.910660  0.892815  \n",
       "1     0.955784  0.943639  \n",
       "2     0.888855  0.880456  \n",
       "3     0.941248  0.932773  \n",
       "4     0.954573  0.820833  \n",
       "5     0.952150  0.918224  \n",
       "6     0.953967  0.943538  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "vectorizers = [sklearn.feature_extraction.text.TfidfVectorizer()] # max_features=1000, stop_words=\"english\"\n",
    "result = compare_vectorizers(vectorizers, models, X_train, y_train, X_test, y_test)\n",
    "\n",
    "display(result)\n",
    "results = pd.concat([results, result], ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a6c0d97",
   "metadata": {},
   "source": [
    "**Analysis**:\n",
    "- The 2 best performing model for TfidfVectorizer are:\n",
    "    - LogisticRegression  (accuracy: 0.937, recall: 0.950)\n",
    "    - BernoulliNB         (accuracy: 0.937, recall: 0.944)\n",
    "- RandomForestClassifier is a good candidate to be considered since has results very close to BernoulliNB\n",
    "- While these results are not far, CountVector seems to perform a bit better without changing configurations."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8efc6d9",
   "metadata": {},
   "source": [
    "#### 4.1.3. Hashing Vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1544885e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>fit_time</th>\n",
       "      <th>vectorizer</th>\n",
       "      <th>accuracy_train</th>\n",
       "      <th>precision_train</th>\n",
       "      <th>recall_train</th>\n",
       "      <th>f1_train</th>\n",
       "      <th>accuracy_test</th>\n",
       "      <th>precision_test</th>\n",
       "      <th>recall_test</th>\n",
       "      <th>f1_test</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>0.000849</td>\n",
       "      <td>TfidfVectorizer</td>\n",
       "      <td>0.930383</td>\n",
       "      <td>0.919407</td>\n",
       "      <td>0.939072</td>\n",
       "      <td>0.929136</td>\n",
       "      <td>0.894305</td>\n",
       "      <td>0.875655</td>\n",
       "      <td>0.910660</td>\n",
       "      <td>0.892815</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>1.781562</td>\n",
       "      <td>TfidfVectorizer</td>\n",
       "      <td>0.961751</td>\n",
       "      <td>0.952973</td>\n",
       "      <td>0.969122</td>\n",
       "      <td>0.960980</td>\n",
       "      <td>0.944810</td>\n",
       "      <td>0.931798</td>\n",
       "      <td>0.955784</td>\n",
       "      <td>0.943639</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>2.279669</td>\n",
       "      <td>TfidfVectorizer</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.883326</td>\n",
       "      <td>0.872214</td>\n",
       "      <td>0.888855</td>\n",
       "      <td>0.880456</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>0.986437</td>\n",
       "      <td>TfidfVectorizer</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.934417</td>\n",
       "      <td>0.924450</td>\n",
       "      <td>0.941248</td>\n",
       "      <td>0.932773</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>1.555851</td>\n",
       "      <td>TfidfVectorizer</td>\n",
       "      <td>0.791442</td>\n",
       "      <td>0.715537</td>\n",
       "      <td>0.947582</td>\n",
       "      <td>0.815372</td>\n",
       "      <td>0.798565</td>\n",
       "      <td>0.719963</td>\n",
       "      <td>0.954573</td>\n",
       "      <td>0.820833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>XGBClassifier</td>\n",
       "      <td>10.548115</td>\n",
       "      <td>TfidfVectorizer</td>\n",
       "      <td>0.932470</td>\n",
       "      <td>0.903110</td>\n",
       "      <td>0.964528</td>\n",
       "      <td>0.932809</td>\n",
       "      <td>0.918021</td>\n",
       "      <td>0.886633</td>\n",
       "      <td>0.952150</td>\n",
       "      <td>0.918224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>BernoulliNB</td>\n",
       "      <td>0.002911</td>\n",
       "      <td>TfidfVectorizer</td>\n",
       "      <td>0.952710</td>\n",
       "      <td>0.939756</td>\n",
       "      <td>0.964528</td>\n",
       "      <td>0.951981</td>\n",
       "      <td>0.944810</td>\n",
       "      <td>0.933333</td>\n",
       "      <td>0.953967</td>\n",
       "      <td>0.943538</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    model   fit_time       vectorizer  accuracy_train  \\\n",
       "0    KNeighborsClassifier   0.000849  TfidfVectorizer        0.930383   \n",
       "1      LogisticRegression   1.781562  TfidfVectorizer        0.961751   \n",
       "2  DecisionTreeClassifier   2.279669  TfidfVectorizer        1.000000   \n",
       "3  RandomForestClassifier   0.986437  TfidfVectorizer        1.000000   \n",
       "4      AdaBoostClassifier   1.555851  TfidfVectorizer        0.791442   \n",
       "5           XGBClassifier  10.548115  TfidfVectorizer        0.932470   \n",
       "6             BernoulliNB   0.002911  TfidfVectorizer        0.952710   \n",
       "\n",
       "   precision_train  recall_train  f1_train  accuracy_test  precision_test  \\\n",
       "0         0.919407      0.939072  0.929136       0.894305        0.875655   \n",
       "1         0.952973      0.969122  0.960980       0.944810        0.931798   \n",
       "2         1.000000      1.000000  1.000000       0.883326        0.872214   \n",
       "3         1.000000      1.000000  1.000000       0.934417        0.924450   \n",
       "4         0.715537      0.947582  0.815372       0.798565        0.719963   \n",
       "5         0.903110      0.964528  0.932809       0.918021        0.886633   \n",
       "6         0.939756      0.964528  0.951981       0.944810        0.933333   \n",
       "\n",
       "   recall_test   f1_test  \n",
       "0     0.910660  0.892815  \n",
       "1     0.955784  0.943639  \n",
       "2     0.888855  0.880456  \n",
       "3     0.941248  0.932773  \n",
       "4     0.954573  0.820833  \n",
       "5     0.952150  0.918224  \n",
       "6     0.953967  0.943538  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "vectorizers = [sklearn.feature_extraction.text.TfidfVectorizer()]\n",
    "result = compare_vectorizers(vectorizers, models, X_train, y_train, X_test, y_test)\n",
    "\n",
    "display(result)\n",
    "results = pd.concat([results, result], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "48971db3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>fit_time</th>\n",
       "      <th>vectorizer</th>\n",
       "      <th>accuracy_train</th>\n",
       "      <th>precision_train</th>\n",
       "      <th>recall_train</th>\n",
       "      <th>f1_train</th>\n",
       "      <th>accuracy_test</th>\n",
       "      <th>precision_test</th>\n",
       "      <th>recall_test</th>\n",
       "      <th>f1_test</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>0.000908</td>\n",
       "      <td>CountVectorizer</td>\n",
       "      <td>0.607298</td>\n",
       "      <td>0.955016</td>\n",
       "      <td>0.201461</td>\n",
       "      <td>0.332732</td>\n",
       "      <td>0.573854</td>\n",
       "      <td>0.896552</td>\n",
       "      <td>0.133858</td>\n",
       "      <td>0.232938</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>4.545018</td>\n",
       "      <td>CountVectorizer</td>\n",
       "      <td>0.981223</td>\n",
       "      <td>0.976199</td>\n",
       "      <td>0.985389</td>\n",
       "      <td>0.980773</td>\n",
       "      <td>0.949349</td>\n",
       "      <td>0.939619</td>\n",
       "      <td>0.956693</td>\n",
       "      <td>0.948079</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>2.364206</td>\n",
       "      <td>CountVectorizer</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.879373</td>\n",
       "      <td>0.881701</td>\n",
       "      <td>0.866747</td>\n",
       "      <td>0.874160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>1.123251</td>\n",
       "      <td>CountVectorizer</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.929732</td>\n",
       "      <td>0.938471</td>\n",
       "      <td>0.914597</td>\n",
       "      <td>0.926380</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>0.562853</td>\n",
       "      <td>CountVectorizer</td>\n",
       "      <td>0.773508</td>\n",
       "      <td>0.694566</td>\n",
       "      <td>0.953080</td>\n",
       "      <td>0.803543</td>\n",
       "      <td>0.782316</td>\n",
       "      <td>0.701086</td>\n",
       "      <td>0.958207</td>\n",
       "      <td>0.809725</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>XGBClassifier</td>\n",
       "      <td>1.214446</td>\n",
       "      <td>CountVectorizer</td>\n",
       "      <td>0.916841</td>\n",
       "      <td>0.880672</td>\n",
       "      <td>0.958804</td>\n",
       "      <td>0.918079</td>\n",
       "      <td>0.908066</td>\n",
       "      <td>0.874510</td>\n",
       "      <td>0.945488</td>\n",
       "      <td>0.908615</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>BernoulliNB</td>\n",
       "      <td>0.002997</td>\n",
       "      <td>CountVectorizer</td>\n",
       "      <td>0.952710</td>\n",
       "      <td>0.939756</td>\n",
       "      <td>0.964528</td>\n",
       "      <td>0.951981</td>\n",
       "      <td>0.944810</td>\n",
       "      <td>0.933333</td>\n",
       "      <td>0.953967</td>\n",
       "      <td>0.943538</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>0.000936</td>\n",
       "      <td>TfidfVectorizer</td>\n",
       "      <td>0.930383</td>\n",
       "      <td>0.919407</td>\n",
       "      <td>0.939072</td>\n",
       "      <td>0.929136</td>\n",
       "      <td>0.894305</td>\n",
       "      <td>0.875655</td>\n",
       "      <td>0.910660</td>\n",
       "      <td>0.892815</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>1.947409</td>\n",
       "      <td>TfidfVectorizer</td>\n",
       "      <td>0.961751</td>\n",
       "      <td>0.952973</td>\n",
       "      <td>0.969122</td>\n",
       "      <td>0.960980</td>\n",
       "      <td>0.944810</td>\n",
       "      <td>0.931798</td>\n",
       "      <td>0.955784</td>\n",
       "      <td>0.943639</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>2.257914</td>\n",
       "      <td>TfidfVectorizer</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.883326</td>\n",
       "      <td>0.872214</td>\n",
       "      <td>0.888855</td>\n",
       "      <td>0.880456</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>0.985260</td>\n",
       "      <td>TfidfVectorizer</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.934417</td>\n",
       "      <td>0.924450</td>\n",
       "      <td>0.941248</td>\n",
       "      <td>0.932773</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>1.547843</td>\n",
       "      <td>TfidfVectorizer</td>\n",
       "      <td>0.791442</td>\n",
       "      <td>0.715537</td>\n",
       "      <td>0.947582</td>\n",
       "      <td>0.815372</td>\n",
       "      <td>0.798565</td>\n",
       "      <td>0.719963</td>\n",
       "      <td>0.954573</td>\n",
       "      <td>0.820833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>XGBClassifier</td>\n",
       "      <td>12.197378</td>\n",
       "      <td>TfidfVectorizer</td>\n",
       "      <td>0.932470</td>\n",
       "      <td>0.903110</td>\n",
       "      <td>0.964528</td>\n",
       "      <td>0.932809</td>\n",
       "      <td>0.918021</td>\n",
       "      <td>0.886633</td>\n",
       "      <td>0.952150</td>\n",
       "      <td>0.918224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>BernoulliNB</td>\n",
       "      <td>0.003238</td>\n",
       "      <td>TfidfVectorizer</td>\n",
       "      <td>0.952710</td>\n",
       "      <td>0.939756</td>\n",
       "      <td>0.964528</td>\n",
       "      <td>0.951981</td>\n",
       "      <td>0.944810</td>\n",
       "      <td>0.933333</td>\n",
       "      <td>0.953967</td>\n",
       "      <td>0.943538</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>0.000849</td>\n",
       "      <td>TfidfVectorizer</td>\n",
       "      <td>0.930383</td>\n",
       "      <td>0.919407</td>\n",
       "      <td>0.939072</td>\n",
       "      <td>0.929136</td>\n",
       "      <td>0.894305</td>\n",
       "      <td>0.875655</td>\n",
       "      <td>0.910660</td>\n",
       "      <td>0.892815</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>1.781562</td>\n",
       "      <td>TfidfVectorizer</td>\n",
       "      <td>0.961751</td>\n",
       "      <td>0.952973</td>\n",
       "      <td>0.969122</td>\n",
       "      <td>0.960980</td>\n",
       "      <td>0.944810</td>\n",
       "      <td>0.931798</td>\n",
       "      <td>0.955784</td>\n",
       "      <td>0.943639</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>2.279669</td>\n",
       "      <td>TfidfVectorizer</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.883326</td>\n",
       "      <td>0.872214</td>\n",
       "      <td>0.888855</td>\n",
       "      <td>0.880456</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>0.986437</td>\n",
       "      <td>TfidfVectorizer</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.934417</td>\n",
       "      <td>0.924450</td>\n",
       "      <td>0.941248</td>\n",
       "      <td>0.932773</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>1.555851</td>\n",
       "      <td>TfidfVectorizer</td>\n",
       "      <td>0.791442</td>\n",
       "      <td>0.715537</td>\n",
       "      <td>0.947582</td>\n",
       "      <td>0.815372</td>\n",
       "      <td>0.798565</td>\n",
       "      <td>0.719963</td>\n",
       "      <td>0.954573</td>\n",
       "      <td>0.820833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>XGBClassifier</td>\n",
       "      <td>10.548115</td>\n",
       "      <td>TfidfVectorizer</td>\n",
       "      <td>0.932470</td>\n",
       "      <td>0.903110</td>\n",
       "      <td>0.964528</td>\n",
       "      <td>0.932809</td>\n",
       "      <td>0.918021</td>\n",
       "      <td>0.886633</td>\n",
       "      <td>0.952150</td>\n",
       "      <td>0.918224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>BernoulliNB</td>\n",
       "      <td>0.002911</td>\n",
       "      <td>TfidfVectorizer</td>\n",
       "      <td>0.952710</td>\n",
       "      <td>0.939756</td>\n",
       "      <td>0.964528</td>\n",
       "      <td>0.951981</td>\n",
       "      <td>0.944810</td>\n",
       "      <td>0.933333</td>\n",
       "      <td>0.953967</td>\n",
       "      <td>0.943538</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     model   fit_time       vectorizer  accuracy_train  \\\n",
       "0     KNeighborsClassifier   0.000908  CountVectorizer        0.607298   \n",
       "1       LogisticRegression   4.545018  CountVectorizer        0.981223   \n",
       "2   DecisionTreeClassifier   2.364206  CountVectorizer        1.000000   \n",
       "3   RandomForestClassifier   1.123251  CountVectorizer        1.000000   \n",
       "4       AdaBoostClassifier   0.562853  CountVectorizer        0.773508   \n",
       "5            XGBClassifier   1.214446  CountVectorizer        0.916841   \n",
       "6              BernoulliNB   0.002997  CountVectorizer        0.952710   \n",
       "7     KNeighborsClassifier   0.000936  TfidfVectorizer        0.930383   \n",
       "8       LogisticRegression   1.947409  TfidfVectorizer        0.961751   \n",
       "9   DecisionTreeClassifier   2.257914  TfidfVectorizer        1.000000   \n",
       "10  RandomForestClassifier   0.985260  TfidfVectorizer        1.000000   \n",
       "11      AdaBoostClassifier   1.547843  TfidfVectorizer        0.791442   \n",
       "12           XGBClassifier  12.197378  TfidfVectorizer        0.932470   \n",
       "13             BernoulliNB   0.003238  TfidfVectorizer        0.952710   \n",
       "14    KNeighborsClassifier   0.000849  TfidfVectorizer        0.930383   \n",
       "15      LogisticRegression   1.781562  TfidfVectorizer        0.961751   \n",
       "16  DecisionTreeClassifier   2.279669  TfidfVectorizer        1.000000   \n",
       "17  RandomForestClassifier   0.986437  TfidfVectorizer        1.000000   \n",
       "18      AdaBoostClassifier   1.555851  TfidfVectorizer        0.791442   \n",
       "19           XGBClassifier  10.548115  TfidfVectorizer        0.932470   \n",
       "20             BernoulliNB   0.002911  TfidfVectorizer        0.952710   \n",
       "\n",
       "    precision_train  recall_train  f1_train  accuracy_test  precision_test  \\\n",
       "0          0.955016      0.201461  0.332732       0.573854        0.896552   \n",
       "1          0.976199      0.985389  0.980773       0.949349        0.939619   \n",
       "2          1.000000      1.000000  1.000000       0.879373        0.881701   \n",
       "3          1.000000      1.000000  1.000000       0.929732        0.938471   \n",
       "4          0.694566      0.953080  0.803543       0.782316        0.701086   \n",
       "5          0.880672      0.958804  0.918079       0.908066        0.874510   \n",
       "6          0.939756      0.964528  0.951981       0.944810        0.933333   \n",
       "7          0.919407      0.939072  0.929136       0.894305        0.875655   \n",
       "8          0.952973      0.969122  0.960980       0.944810        0.931798   \n",
       "9          1.000000      1.000000  1.000000       0.883326        0.872214   \n",
       "10         1.000000      1.000000  1.000000       0.934417        0.924450   \n",
       "11         0.715537      0.947582  0.815372       0.798565        0.719963   \n",
       "12         0.903110      0.964528  0.932809       0.918021        0.886633   \n",
       "13         0.939756      0.964528  0.951981       0.944810        0.933333   \n",
       "14         0.919407      0.939072  0.929136       0.894305        0.875655   \n",
       "15         0.952973      0.969122  0.960980       0.944810        0.931798   \n",
       "16         1.000000      1.000000  1.000000       0.883326        0.872214   \n",
       "17         1.000000      1.000000  1.000000       0.934417        0.924450   \n",
       "18         0.715537      0.947582  0.815372       0.798565        0.719963   \n",
       "19         0.903110      0.964528  0.932809       0.918021        0.886633   \n",
       "20         0.939756      0.964528  0.951981       0.944810        0.933333   \n",
       "\n",
       "    recall_test   f1_test  \n",
       "0      0.133858  0.232938  \n",
       "1      0.956693  0.948079  \n",
       "2      0.866747  0.874160  \n",
       "3      0.914597  0.926380  \n",
       "4      0.958207  0.809725  \n",
       "5      0.945488  0.908615  \n",
       "6      0.953967  0.943538  \n",
       "7      0.910660  0.892815  \n",
       "8      0.955784  0.943639  \n",
       "9      0.888855  0.880456  \n",
       "10     0.941248  0.932773  \n",
       "11     0.954573  0.820833  \n",
       "12     0.952150  0.918224  \n",
       "13     0.953967  0.943538  \n",
       "14     0.910660  0.892815  \n",
       "15     0.955784  0.943639  \n",
       "16     0.888855  0.880456  \n",
       "17     0.941248  0.932773  \n",
       "18     0.954573  0.820833  \n",
       "19     0.952150  0.918224  \n",
       "20     0.953967  0.943538  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "results.to_csv(\"./output/improve_pred_results.csv\")\n",
    "display(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "131c1b60",
   "metadata": {},
   "source": [
    "**Analysis**:\n",
    "- The 2 best performing model for TfidfVectorizer are:\n",
    "    - RandomForestClassifier (accuracy: 0.948, recall: 0.955): \n",
    "    - LogisticRegression (accuracy: 0.929, recall: 0.947):\n",
    "- Hashing Vectorizer together with Random Forest Generator show the best results for accuracy but slightly less recall than Logistic Regressor with Count Vetorizer."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e2888a3",
   "metadata": {},
   "source": [
    "### 4.2 N-Gram Analysis for the Top-Performing Models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04b7e2ed",
   "metadata": {},
   "source": [
    "#### 4.2.1. LogisticRegression + CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a9bf2c3b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>fit_time</th>\n",
       "      <th>vectorizer</th>\n",
       "      <th>ngram_range</th>\n",
       "      <th>accuracy_train</th>\n",
       "      <th>precision_train</th>\n",
       "      <th>recall_train</th>\n",
       "      <th>f1_train</th>\n",
       "      <th>accuracy_test</th>\n",
       "      <th>precision_test</th>\n",
       "      <th>recall_test</th>\n",
       "      <th>f1_test</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>4.904252</td>\n",
       "      <td>CountVectorizer</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>0.981223</td>\n",
       "      <td>0.976199</td>\n",
       "      <td>0.985389</td>\n",
       "      <td>0.980773</td>\n",
       "      <td>0.949349</td>\n",
       "      <td>0.939619</td>\n",
       "      <td>0.956693</td>\n",
       "      <td>0.948079</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>5.254913</td>\n",
       "      <td>CountVectorizer</td>\n",
       "      <td>(1, 2)</td>\n",
       "      <td>0.998243</td>\n",
       "      <td>0.996845</td>\n",
       "      <td>0.999548</td>\n",
       "      <td>0.998195</td>\n",
       "      <td>0.952862</td>\n",
       "      <td>0.940828</td>\n",
       "      <td>0.963053</td>\n",
       "      <td>0.951811</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>3.619610</td>\n",
       "      <td>CountVectorizer</td>\n",
       "      <td>(2, 2)</td>\n",
       "      <td>0.995352</td>\n",
       "      <td>0.991626</td>\n",
       "      <td>0.998870</td>\n",
       "      <td>0.995235</td>\n",
       "      <td>0.901186</td>\n",
       "      <td>0.864962</td>\n",
       "      <td>0.942762</td>\n",
       "      <td>0.902188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>4.721386</td>\n",
       "      <td>CountVectorizer</td>\n",
       "      <td>(1, 3)</td>\n",
       "      <td>0.999378</td>\n",
       "      <td>0.998721</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.999360</td>\n",
       "      <td>0.950227</td>\n",
       "      <td>0.937389</td>\n",
       "      <td>0.961236</td>\n",
       "      <td>0.949163</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>4.223055</td>\n",
       "      <td>CountVectorizer</td>\n",
       "      <td>(2, 3)</td>\n",
       "      <td>0.997950</td>\n",
       "      <td>0.995800</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.997896</td>\n",
       "      <td>0.897087</td>\n",
       "      <td>0.856516</td>\n",
       "      <td>0.945488</td>\n",
       "      <td>0.898805</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>5.531452</td>\n",
       "      <td>CountVectorizer</td>\n",
       "      <td>(3, 3)</td>\n",
       "      <td>0.995205</td>\n",
       "      <td>0.990230</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.995091</td>\n",
       "      <td>0.769580</td>\n",
       "      <td>0.686932</td>\n",
       "      <td>0.961538</td>\n",
       "      <td>0.801363</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                model  fit_time       vectorizer ngram_range  accuracy_train  \\\n",
       "0  LogisticRegression  4.904252  CountVectorizer      (1, 1)        0.981223   \n",
       "1  LogisticRegression  5.254913  CountVectorizer      (1, 2)        0.998243   \n",
       "2  LogisticRegression  3.619610  CountVectorizer      (2, 2)        0.995352   \n",
       "3  LogisticRegression  4.721386  CountVectorizer      (1, 3)        0.999378   \n",
       "4  LogisticRegression  4.223055  CountVectorizer      (2, 3)        0.997950   \n",
       "5  LogisticRegression  5.531452  CountVectorizer      (3, 3)        0.995205   \n",
       "\n",
       "   precision_train  recall_train  f1_train  accuracy_test  precision_test  \\\n",
       "0         0.976199      0.985389  0.980773       0.949349        0.939619   \n",
       "1         0.996845      0.999548  0.998195       0.952862        0.940828   \n",
       "2         0.991626      0.998870  0.995235       0.901186        0.864962   \n",
       "3         0.998721      1.000000  0.999360       0.950227        0.937389   \n",
       "4         0.995800      1.000000  0.997896       0.897087        0.856516   \n",
       "5         0.990230      1.000000  0.995091       0.769580        0.686932   \n",
       "\n",
       "   recall_test   f1_test  \n",
       "0     0.956693  0.948079  \n",
       "1     0.963053  0.951811  \n",
       "2     0.942762  0.902188  \n",
       "3     0.961236  0.949163  \n",
       "4     0.945488  0.898805  \n",
       "5     0.961538  0.801363  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "models = [sklearn.linear_model.LogisticRegression(random_state=seed)]\n",
    "ngrams = [(1,1), (1,2), (2,2), (1,3), (2,3), (3,3)]\n",
    "vectorizers = [sklearn.feature_extraction.text.CountVectorizer(ngram_range=ngram) for ngram in ngrams]\n",
    "\n",
    "results = compare_vectorizers(vectorizers, models, X_train, y_train, X_test, y_test, inc_params=[\"ngram_range\"])\n",
    "display(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69816dc2",
   "metadata": {},
   "source": [
    "**Analysis**:\n",
    "- Best results for LogisticRegression and CountVectorizer is use unigrams and bigrams (accuracy: 0.950, recall: 0.961)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "386e5084",
   "metadata": {},
   "source": [
    "#### 4.2.2. RandomForestClassifier + HashingVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0dd9f1d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>fit_time</th>\n",
       "      <th>vectorizer</th>\n",
       "      <th>ngram_range</th>\n",
       "      <th>accuracy_train</th>\n",
       "      <th>precision_train</th>\n",
       "      <th>recall_train</th>\n",
       "      <th>f1_train</th>\n",
       "      <th>accuracy_test</th>\n",
       "      <th>precision_test</th>\n",
       "      <th>recall_test</th>\n",
       "      <th>f1_test</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>1.005639</td>\n",
       "      <td>TfidfVectorizer</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.934417</td>\n",
       "      <td>0.924450</td>\n",
       "      <td>0.941248</td>\n",
       "      <td>0.932773</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>4.583967</td>\n",
       "      <td>TfidfVectorizer</td>\n",
       "      <td>(1, 2)</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.913043</td>\n",
       "      <td>0.889528</td>\n",
       "      <td>0.936402</td>\n",
       "      <td>0.912364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>6.214324</td>\n",
       "      <td>TfidfVectorizer</td>\n",
       "      <td>(2, 2)</td>\n",
       "      <td>0.999817</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.999623</td>\n",
       "      <td>0.999812</td>\n",
       "      <td>0.805299</td>\n",
       "      <td>0.856988</td>\n",
       "      <td>0.716838</td>\n",
       "      <td>0.780673</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>10.037241</td>\n",
       "      <td>TfidfVectorizer</td>\n",
       "      <td>(1, 3)</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.904699</td>\n",
       "      <td>0.885208</td>\n",
       "      <td>0.922471</td>\n",
       "      <td>0.903455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>27.188731</td>\n",
       "      <td>TfidfVectorizer</td>\n",
       "      <td>(2, 3)</td>\n",
       "      <td>0.999780</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.999548</td>\n",
       "      <td>0.999774</td>\n",
       "      <td>0.798273</td>\n",
       "      <td>0.854197</td>\n",
       "      <td>0.702604</td>\n",
       "      <td>0.771020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>15.372178</td>\n",
       "      <td>TfidfVectorizer</td>\n",
       "      <td>(3, 3)</td>\n",
       "      <td>0.998902</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.997741</td>\n",
       "      <td>0.998869</td>\n",
       "      <td>0.636364</td>\n",
       "      <td>0.904950</td>\n",
       "      <td>0.276802</td>\n",
       "      <td>0.423933</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    model   fit_time       vectorizer ngram_range  \\\n",
       "0  RandomForestClassifier   1.005639  TfidfVectorizer      (1, 1)   \n",
       "1  RandomForestClassifier   4.583967  TfidfVectorizer      (1, 2)   \n",
       "2  RandomForestClassifier   6.214324  TfidfVectorizer      (2, 2)   \n",
       "3  RandomForestClassifier  10.037241  TfidfVectorizer      (1, 3)   \n",
       "4  RandomForestClassifier  27.188731  TfidfVectorizer      (2, 3)   \n",
       "5  RandomForestClassifier  15.372178  TfidfVectorizer      (3, 3)   \n",
       "\n",
       "   accuracy_train  precision_train  recall_train  f1_train  accuracy_test  \\\n",
       "0        1.000000              1.0      1.000000  1.000000       0.934417   \n",
       "1        1.000000              1.0      1.000000  1.000000       0.913043   \n",
       "2        0.999817              1.0      0.999623  0.999812       0.805299   \n",
       "3        1.000000              1.0      1.000000  1.000000       0.904699   \n",
       "4        0.999780              1.0      0.999548  0.999774       0.798273   \n",
       "5        0.998902              1.0      0.997741  0.998869       0.636364   \n",
       "\n",
       "   precision_test  recall_test   f1_test  \n",
       "0        0.924450     0.941248  0.932773  \n",
       "1        0.889528     0.936402  0.912364  \n",
       "2        0.856988     0.716838  0.780673  \n",
       "3        0.885208     0.922471  0.903455  \n",
       "4        0.854197     0.702604  0.771020  \n",
       "5        0.904950     0.276802  0.423933  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "models = [sklearn.ensemble.RandomForestClassifier(random_state=seed, n_jobs=-1)]\n",
    "ngrams = [(1,1), (1,2), (2,2), (1,3), (2,3), (3,3)]\n",
    "vectorizers = [sklearn.feature_extraction.text.TfidfVectorizer(ngram_range=ngram) for ngram in ngrams]\n",
    "\n",
    "result = compare_vectorizers(vectorizers, models, X_train, y_train, X_test, y_test, inc_params=[\"ngram_range\"])\n",
    "\n",
    "display(result)\n",
    "results = pd.concat([results, result], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8eb68262",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>fit_time</th>\n",
       "      <th>vectorizer</th>\n",
       "      <th>ngram_range</th>\n",
       "      <th>accuracy_train</th>\n",
       "      <th>precision_train</th>\n",
       "      <th>recall_train</th>\n",
       "      <th>f1_train</th>\n",
       "      <th>accuracy_test</th>\n",
       "      <th>precision_test</th>\n",
       "      <th>recall_test</th>\n",
       "      <th>f1_test</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>4.904252</td>\n",
       "      <td>CountVectorizer</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>0.981223</td>\n",
       "      <td>0.976199</td>\n",
       "      <td>0.985389</td>\n",
       "      <td>0.980773</td>\n",
       "      <td>0.949349</td>\n",
       "      <td>0.939619</td>\n",
       "      <td>0.956693</td>\n",
       "      <td>0.948079</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>5.254913</td>\n",
       "      <td>CountVectorizer</td>\n",
       "      <td>(1, 2)</td>\n",
       "      <td>0.998243</td>\n",
       "      <td>0.996845</td>\n",
       "      <td>0.999548</td>\n",
       "      <td>0.998195</td>\n",
       "      <td>0.952862</td>\n",
       "      <td>0.940828</td>\n",
       "      <td>0.963053</td>\n",
       "      <td>0.951811</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>3.619610</td>\n",
       "      <td>CountVectorizer</td>\n",
       "      <td>(2, 2)</td>\n",
       "      <td>0.995352</td>\n",
       "      <td>0.991626</td>\n",
       "      <td>0.998870</td>\n",
       "      <td>0.995235</td>\n",
       "      <td>0.901186</td>\n",
       "      <td>0.864962</td>\n",
       "      <td>0.942762</td>\n",
       "      <td>0.902188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>4.721386</td>\n",
       "      <td>CountVectorizer</td>\n",
       "      <td>(1, 3)</td>\n",
       "      <td>0.999378</td>\n",
       "      <td>0.998721</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.999360</td>\n",
       "      <td>0.950227</td>\n",
       "      <td>0.937389</td>\n",
       "      <td>0.961236</td>\n",
       "      <td>0.949163</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>4.223055</td>\n",
       "      <td>CountVectorizer</td>\n",
       "      <td>(2, 3)</td>\n",
       "      <td>0.997950</td>\n",
       "      <td>0.995800</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.997896</td>\n",
       "      <td>0.897087</td>\n",
       "      <td>0.856516</td>\n",
       "      <td>0.945488</td>\n",
       "      <td>0.898805</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>5.531452</td>\n",
       "      <td>CountVectorizer</td>\n",
       "      <td>(3, 3)</td>\n",
       "      <td>0.995205</td>\n",
       "      <td>0.990230</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.995091</td>\n",
       "      <td>0.769580</td>\n",
       "      <td>0.686932</td>\n",
       "      <td>0.961538</td>\n",
       "      <td>0.801363</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>1.005639</td>\n",
       "      <td>TfidfVectorizer</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.934417</td>\n",
       "      <td>0.924450</td>\n",
       "      <td>0.941248</td>\n",
       "      <td>0.932773</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>4.583967</td>\n",
       "      <td>TfidfVectorizer</td>\n",
       "      <td>(1, 2)</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.913043</td>\n",
       "      <td>0.889528</td>\n",
       "      <td>0.936402</td>\n",
       "      <td>0.912364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>6.214324</td>\n",
       "      <td>TfidfVectorizer</td>\n",
       "      <td>(2, 2)</td>\n",
       "      <td>0.999817</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.999623</td>\n",
       "      <td>0.999812</td>\n",
       "      <td>0.805299</td>\n",
       "      <td>0.856988</td>\n",
       "      <td>0.716838</td>\n",
       "      <td>0.780673</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>10.037241</td>\n",
       "      <td>TfidfVectorizer</td>\n",
       "      <td>(1, 3)</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.904699</td>\n",
       "      <td>0.885208</td>\n",
       "      <td>0.922471</td>\n",
       "      <td>0.903455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>27.188731</td>\n",
       "      <td>TfidfVectorizer</td>\n",
       "      <td>(2, 3)</td>\n",
       "      <td>0.999780</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.999548</td>\n",
       "      <td>0.999774</td>\n",
       "      <td>0.798273</td>\n",
       "      <td>0.854197</td>\n",
       "      <td>0.702604</td>\n",
       "      <td>0.771020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>15.372178</td>\n",
       "      <td>TfidfVectorizer</td>\n",
       "      <td>(3, 3)</td>\n",
       "      <td>0.998902</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.997741</td>\n",
       "      <td>0.998869</td>\n",
       "      <td>0.636364</td>\n",
       "      <td>0.904950</td>\n",
       "      <td>0.276802</td>\n",
       "      <td>0.423933</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     model   fit_time       vectorizer ngram_range  \\\n",
       "0       LogisticRegression   4.904252  CountVectorizer      (1, 1)   \n",
       "1       LogisticRegression   5.254913  CountVectorizer      (1, 2)   \n",
       "2       LogisticRegression   3.619610  CountVectorizer      (2, 2)   \n",
       "3       LogisticRegression   4.721386  CountVectorizer      (1, 3)   \n",
       "4       LogisticRegression   4.223055  CountVectorizer      (2, 3)   \n",
       "5       LogisticRegression   5.531452  CountVectorizer      (3, 3)   \n",
       "6   RandomForestClassifier   1.005639  TfidfVectorizer      (1, 1)   \n",
       "7   RandomForestClassifier   4.583967  TfidfVectorizer      (1, 2)   \n",
       "8   RandomForestClassifier   6.214324  TfidfVectorizer      (2, 2)   \n",
       "9   RandomForestClassifier  10.037241  TfidfVectorizer      (1, 3)   \n",
       "10  RandomForestClassifier  27.188731  TfidfVectorizer      (2, 3)   \n",
       "11  RandomForestClassifier  15.372178  TfidfVectorizer      (3, 3)   \n",
       "\n",
       "    accuracy_train  precision_train  recall_train  f1_train  accuracy_test  \\\n",
       "0         0.981223         0.976199      0.985389  0.980773       0.949349   \n",
       "1         0.998243         0.996845      0.999548  0.998195       0.952862   \n",
       "2         0.995352         0.991626      0.998870  0.995235       0.901186   \n",
       "3         0.999378         0.998721      1.000000  0.999360       0.950227   \n",
       "4         0.997950         0.995800      1.000000  0.997896       0.897087   \n",
       "5         0.995205         0.990230      1.000000  0.995091       0.769580   \n",
       "6         1.000000         1.000000      1.000000  1.000000       0.934417   \n",
       "7         1.000000         1.000000      1.000000  1.000000       0.913043   \n",
       "8         0.999817         1.000000      0.999623  0.999812       0.805299   \n",
       "9         1.000000         1.000000      1.000000  1.000000       0.904699   \n",
       "10        0.999780         1.000000      0.999548  0.999774       0.798273   \n",
       "11        0.998902         1.000000      0.997741  0.998869       0.636364   \n",
       "\n",
       "    precision_test  recall_test   f1_test  \n",
       "0         0.939619     0.956693  0.948079  \n",
       "1         0.940828     0.963053  0.951811  \n",
       "2         0.864962     0.942762  0.902188  \n",
       "3         0.937389     0.961236  0.949163  \n",
       "4         0.856516     0.945488  0.898805  \n",
       "5         0.686932     0.961538  0.801363  \n",
       "6         0.924450     0.941248  0.932773  \n",
       "7         0.889528     0.936402  0.912364  \n",
       "8         0.856988     0.716838  0.780673  \n",
       "9         0.885208     0.922471  0.903455  \n",
       "10        0.854197     0.702604  0.771020  \n",
       "11        0.904950     0.276802  0.423933  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "results.to_csv(\"./output/n-grams_results.csv\")\n",
    "display(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38732001",
   "metadata": {},
   "source": [
    "**Analysis**:\n",
    "- RandomForestClassifier + TfidfVectorizer best results are with unigrams being these a bit bellow the other model (Accuracy: 0.932, Recall: 0.936)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3046d60",
   "metadata": {},
   "source": [
    "### 5. Current Best ML Model Validation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "367e912c",
   "metadata": {},
   "source": [
    "After seeing the results of the premade models and given the best results we got were based on a LogisticRegression we assume there are some words in the dataset hevily influencing the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "21df7784",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accuracy_train</th>\n",
       "      <th>precision_train</th>\n",
       "      <th>recall_train</th>\n",
       "      <th>f1_train</th>\n",
       "      <th>accuracy_test</th>\n",
       "      <th>precision_test</th>\n",
       "      <th>recall_test</th>\n",
       "      <th>f1_test</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.998243</td>\n",
       "      <td>0.996845</td>\n",
       "      <td>0.999548</td>\n",
       "      <td>0.998195</td>\n",
       "      <td>0.952862</td>\n",
       "      <td>0.940828</td>\n",
       "      <td>0.963053</td>\n",
       "      <td>0.951811</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   accuracy_train  precision_train  recall_train  f1_train  accuracy_test  \\\n",
       "0        0.998243         0.996845      0.999548  0.998195       0.952862   \n",
       "\n",
       "   precision_test  recall_test   f1_test  \n",
       "0        0.940828     0.963053  0.951811  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Let's first train the logistic regressor\n",
    "lr = sklearn.linear_model.LogisticRegression(random_state=seed)\n",
    "cv = sklearn.feature_extraction.text.CountVectorizer(ngram_range = (1, 2))\n",
    "\n",
    "mv_train_df = cv.fit_transform(X_train)\n",
    "mv_test_df  = cv.transform(X_test)\n",
    "\n",
    "lr.fit(mv_train_df, y_train)\n",
    "\n",
    "y_train_predict = lr.predict(mv_train_df)\n",
    "y_test_predict = lr.predict(mv_test_df)\n",
    "\n",
    "result = get_classifier_metrics(y_train, y_train_predict , sub_name=\"_train\") | get_classifier_metrics(y_test, y_test_predict , sub_name=\"_test\") \n",
    "display(pd.DataFrame.from_dict(result, orient='index').T)\n",
    "\n",
    "# Get the coeficients and the features from the model and vectorizer\n",
    "coefs = lr.coef_[0]\n",
    "features = cv.get_feature_names_out()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7d9512c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>coef</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>49321</th>\n",
       "      <td>factbox</td>\n",
       "      <td>3.182219</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127033</th>\n",
       "      <td>says</td>\n",
       "      <td>2.709662</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>157549</th>\n",
       "      <td>urges</td>\n",
       "      <td>2.001461</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147551</th>\n",
       "      <td>tillerson</td>\n",
       "      <td>1.741403</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82476</th>\n",
       "      <td>lawmakers</td>\n",
       "      <td>1.733302</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>141728</th>\n",
       "      <td>talks</td>\n",
       "      <td>1.730247</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26569</th>\n",
       "      <td>china</td>\n",
       "      <td>1.727194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47074</th>\n",
       "      <td>eu</td>\n",
       "      <td>1.723963</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168852</th>\n",
       "      <td>zimbabwe</td>\n",
       "      <td>1.693987</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>136309</th>\n",
       "      <td>spokesman</td>\n",
       "      <td>1.622523</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             word      coef\n",
       "49321     factbox  3.182219\n",
       "127033       says  2.709662\n",
       "157549      urges  2.001461\n",
       "147551  tillerson  1.741403\n",
       "82476   lawmakers  1.733302\n",
       "141728      talks  1.730247\n",
       "26569       china  1.727194\n",
       "47074          eu  1.723963\n",
       "168852   zimbabwe  1.693987\n",
       "136309  spokesman  1.622523"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>coef</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>158962</th>\n",
       "      <td>video</td>\n",
       "      <td>-4.307516</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19445</th>\n",
       "      <td>breaking</td>\n",
       "      <td>-4.102125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60141</th>\n",
       "      <td>gop</td>\n",
       "      <td>-3.593094</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66407</th>\n",
       "      <td>hillary</td>\n",
       "      <td>-3.400183</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79005</th>\n",
       "      <td>just</td>\n",
       "      <td>-3.086532</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117247</th>\n",
       "      <td>racist</td>\n",
       "      <td>-2.433639</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38121</th>\n",
       "      <td>dem</td>\n",
       "      <td>-2.108554</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69683</th>\n",
       "      <td>huge</td>\n",
       "      <td>-2.043482</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>167531</th>\n",
       "      <td>wow</td>\n",
       "      <td>-1.976108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18423</th>\n",
       "      <td>bombshell</td>\n",
       "      <td>-1.911474</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             word      coef\n",
       "158962      video -4.307516\n",
       "19445    breaking -4.102125\n",
       "60141         gop -3.593094\n",
       "66407     hillary -3.400183\n",
       "79005        just -3.086532\n",
       "117247     racist -2.433639\n",
       "38121         dem -2.108554\n",
       "69683        huge -2.043482\n",
       "167531        wow -1.976108\n",
       "18423   bombshell -1.911474"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Review the most influencial words for the predictions\n",
    "word_coefs = pd.DataFrame(zip(features, coefs))\n",
    "word_coefs.columns = [\"word\", \"coef\"]\n",
    "\n",
    "# See the top 10 words with more coeficient\n",
    "display(word_coefs.sort_values(\"coef\", ascending=False)[0:10])\n",
    "\n",
    "# See the top 10 words with less coeficient\n",
    "display(word_coefs.sort_values(\"coef\", ascending=True)[0:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a862b8e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accuracy_train</th>\n",
       "      <th>precision_train</th>\n",
       "      <th>recall_train</th>\n",
       "      <th>f1_train</th>\n",
       "      <th>accuracy_test</th>\n",
       "      <th>precision_test</th>\n",
       "      <th>recall_test</th>\n",
       "      <th>f1_test</th>\n",
       "      <th>coef_thld_rm</th>\n",
       "      <th>num_words_rm</th>\n",
       "      <th>prop_words_rm</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.998243</td>\n",
       "      <td>0.996845</td>\n",
       "      <td>0.999548</td>\n",
       "      <td>0.998195</td>\n",
       "      <td>0.940419</td>\n",
       "      <td>0.917027</td>\n",
       "      <td>0.963961</td>\n",
       "      <td>0.939908</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.000012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.998243</td>\n",
       "      <td>0.996845</td>\n",
       "      <td>0.999548</td>\n",
       "      <td>0.998195</td>\n",
       "      <td>0.937052</td>\n",
       "      <td>0.910990</td>\n",
       "      <td>0.963961</td>\n",
       "      <td>0.936727</td>\n",
       "      <td>3.5</td>\n",
       "      <td>3</td>\n",
       "      <td>0.000018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.998243</td>\n",
       "      <td>0.996845</td>\n",
       "      <td>0.999548</td>\n",
       "      <td>0.998195</td>\n",
       "      <td>0.927536</td>\n",
       "      <td>0.894574</td>\n",
       "      <td>0.963658</td>\n",
       "      <td>0.927832</td>\n",
       "      <td>3.0</td>\n",
       "      <td>6</td>\n",
       "      <td>0.000035</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.998243</td>\n",
       "      <td>0.996845</td>\n",
       "      <td>0.999548</td>\n",
       "      <td>0.998195</td>\n",
       "      <td>0.925194</td>\n",
       "      <td>0.898828</td>\n",
       "      <td>0.952453</td>\n",
       "      <td>0.924864</td>\n",
       "      <td>2.5</td>\n",
       "      <td>7</td>\n",
       "      <td>0.000041</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.998243</td>\n",
       "      <td>0.996845</td>\n",
       "      <td>0.999548</td>\n",
       "      <td>0.998195</td>\n",
       "      <td>0.924608</td>\n",
       "      <td>0.897575</td>\n",
       "      <td>0.952756</td>\n",
       "      <td>0.924343</td>\n",
       "      <td>2.0</td>\n",
       "      <td>11</td>\n",
       "      <td>0.000065</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.998243</td>\n",
       "      <td>0.996845</td>\n",
       "      <td>0.999548</td>\n",
       "      <td>0.998195</td>\n",
       "      <td>0.907627</td>\n",
       "      <td>0.871282</td>\n",
       "      <td>0.949122</td>\n",
       "      <td>0.908537</td>\n",
       "      <td>1.5</td>\n",
       "      <td>43</td>\n",
       "      <td>0.000254</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.998243</td>\n",
       "      <td>0.996845</td>\n",
       "      <td>0.999548</td>\n",
       "      <td>0.998195</td>\n",
       "      <td>0.844971</td>\n",
       "      <td>0.784140</td>\n",
       "      <td>0.937311</td>\n",
       "      <td>0.853911</td>\n",
       "      <td>1.0</td>\n",
       "      <td>222</td>\n",
       "      <td>0.001313</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.998243</td>\n",
       "      <td>0.996845</td>\n",
       "      <td>0.999548</td>\n",
       "      <td>0.998195</td>\n",
       "      <td>0.701069</td>\n",
       "      <td>0.625498</td>\n",
       "      <td>0.950939</td>\n",
       "      <td>0.754626</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1371</td>\n",
       "      <td>0.008111</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   accuracy_train  precision_train  recall_train  f1_train  accuracy_test  \\\n",
       "7        0.998243         0.996845      0.999548  0.998195       0.940419   \n",
       "6        0.998243         0.996845      0.999548  0.998195       0.937052   \n",
       "5        0.998243         0.996845      0.999548  0.998195       0.927536   \n",
       "4        0.998243         0.996845      0.999548  0.998195       0.925194   \n",
       "3        0.998243         0.996845      0.999548  0.998195       0.924608   \n",
       "2        0.998243         0.996845      0.999548  0.998195       0.907627   \n",
       "1        0.998243         0.996845      0.999548  0.998195       0.844971   \n",
       "0        0.998243         0.996845      0.999548  0.998195       0.701069   \n",
       "\n",
       "   precision_test  recall_test   f1_test  coef_thld_rm  num_words_rm  \\\n",
       "7        0.917027     0.963961  0.939908           4.0             2   \n",
       "6        0.910990     0.963961  0.936727           3.5             3   \n",
       "5        0.894574     0.963658  0.927832           3.0             6   \n",
       "4        0.898828     0.952453  0.924864           2.5             7   \n",
       "3        0.897575     0.952756  0.924343           2.0            11   \n",
       "2        0.871282     0.949122  0.908537           1.5            43   \n",
       "1        0.784140     0.937311  0.853911           1.0           222   \n",
       "0        0.625498     0.950939  0.754626           0.5          1371   \n",
       "\n",
       "   prop_words_rm  \n",
       "7       0.000012  \n",
       "6       0.000018  \n",
       "5       0.000035  \n",
       "4       0.000041  \n",
       "3       0.000065  \n",
       "2       0.000254  \n",
       "1       0.001313  \n",
       "0       0.008111  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Let's try the model by removing parts of it\n",
    "def remove_words(serie, words):\n",
    "    return serie.apply(lambda x: ' '.join([w for w in x.split() if w not in words]))\n",
    "\n",
    "results = []\n",
    "for i in range(5, 41, 5):\n",
    "    c = i / 10\n",
    "    words = list(word_coefs.loc[(word_coefs[\"coef\"] > c) | (word_coefs[\"coef\"] < c * -1), \"word\"])\n",
    "    y_test_predict = lr.predict(cv.transform(remove_words(X_test, words)))\n",
    "    result[\"coef_thld_rm\"] = c \n",
    "    result[\"num_words_rm\"] = len(words)\n",
    "    result[\"prop_words_rm\"] = len(words) / word_coefs.shape[0]\n",
    "    results.append(result | get_classifier_metrics(y_test, y_test_predict , sub_name=\"_test\"))\n",
    "\n",
    "results = pd.DataFrame(results).sort_values(\"coef_thld_rm\", ascending=False)\n",
    "display(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6e1e081",
   "metadata": {},
   "source": [
    "**Analysis**:\n",
    "- After removing the words iterativelly based on the coeficient of the words we see a decrease in accuracy (0.844 by keeping only words with coeficient inbetween -1 and 1)\n",
    "- The recall stays relevant in between 0.937 and 0.963 \n",
    "- This test shows that the model is "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb8f1e7b",
   "metadata": {},
   "source": [
    "## 6. Pre-Trained Transformers models experimentation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14047f62",
   "metadata": {},
   "source": [
    "### 6.1. Bert tiny fine-tunned fake news detector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e9e51a30",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n",
      "You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>mrm8488/bert-tiny-finetuned-fake-news-detection</td>\n",
       "      <td>0.465214</td>\n",
       "      <td>0.474819</td>\n",
       "      <td>0.9576</td>\n",
       "      <td>0.634851</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             model  accuracy precision  \\\n",
       "0  mrm8488/bert-tiny-finetuned-fake-news-detection  0.465214  0.474819   \n",
       "\n",
       "   recall        f1  \n",
       "0  0.9576  0.634851  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "# FAKE NEWS DETECTOR\n",
    "pipe = pipeline(\"text-classification\", model=\"mrm8488/bert-tiny-finetuned-fake-news-detection\", device=0)\n",
    "\n",
    "predictions = []\n",
    "for text in train_df[\"corpus\"]:\n",
    "    predictions.append(0 if pipe(text)[0][\"label\"] == \"LABEL_0\" else 1)\n",
    "\n",
    "results = get_classifier_metrics(train_df[\"label\"], predictions)\n",
    "results = {\"model\": \"mrm8488/bert-tiny-finetuned-fake-news-detection\"} | results\n",
    "results = pd.DataFrame.from_dict(results, orient='index').T\n",
    "display(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "855cb669",
   "metadata": {},
   "source": [
    "### 6.2. Fake news Bert detect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "18b6c85e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>jy46604790/Fake-News-Bert-Detect</td>\n",
       "      <td>0.652319</td>\n",
       "      <td>0.983162</td>\n",
       "      <td>0.288782</td>\n",
       "      <td>0.446434</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              model  accuracy precision    recall        f1\n",
       "0  jy46604790/Fake-News-Bert-Detect  0.652319  0.983162  0.288782  0.446434"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "MODEL_bert = \"jy46604790/Fake-News-Bert-Detect\"\n",
    "clf_bert = pipeline(\"text-classification\", model=MODEL_bert, tokenizer=MODEL_bert, device=0)\n",
    "\n",
    "text_bert = train_df[\"corpus\"].tolist()\n",
    "result_bert = clf_bert(text_bert)\n",
    "predictions_bert = [0 if r[\"label\"] == \"LABEL_0\" else 1 for r in result_bert]\n",
    "\n",
    "result = get_classifier_metrics(train_df[\"label\"], predictions_bert)\n",
    "result = {\"model\": MODEL_bert} | result\n",
    "result = pd.DataFrame.from_dict(result, orient='index').T\n",
    "\n",
    "display(result)\n",
    "results = pd.concat([results, result], ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63db4d91",
   "metadata": {},
   "source": [
    "### 6.3. Distil Bert fake news"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b833d8ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>yasmine-11/distilbert_fake_news</td>\n",
       "      <td>0.484426</td>\n",
       "      <td>0.485065</td>\n",
       "      <td>0.988176</td>\n",
       "      <td>0.650714</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             model  accuracy precision    recall        f1\n",
       "0  yasmine-11/distilbert_fake_news  0.484426  0.485065  0.988176  0.650714"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "MODEL_dist = \"yasmine-11/distilbert_fake_news\"\n",
    "clf_dist = pipeline(\"text-classification\", model=MODEL_dist, tokenizer=MODEL_dist, device=0)\n",
    "\n",
    "text_dist = X_train.tolist()\n",
    "result_dist = clf_dist(text_dist)\n",
    "predictions_dist = [0 if r[\"label\"] == \"LABEL_0\" else 1 for r in result_dist]\n",
    "\n",
    "result = get_classifier_metrics(y_train, predictions_dist)\n",
    "result = {\"model\": MODEL_dist} | result\n",
    "result = pd.DataFrame.from_dict(result, orient='index').T\n",
    "\n",
    "display(result)\n",
    "results = pd.concat([results, result], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "84bf9a6e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>mrm8488/bert-tiny-finetuned-fake-news-detection</td>\n",
       "      <td>0.465214</td>\n",
       "      <td>0.474819</td>\n",
       "      <td>0.9576</td>\n",
       "      <td>0.634851</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>jy46604790/Fake-News-Bert-Detect</td>\n",
       "      <td>0.652319</td>\n",
       "      <td>0.983162</td>\n",
       "      <td>0.288782</td>\n",
       "      <td>0.446434</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>yasmine-11/distilbert_fake_news</td>\n",
       "      <td>0.484426</td>\n",
       "      <td>0.485065</td>\n",
       "      <td>0.988176</td>\n",
       "      <td>0.650714</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             model  accuracy precision  \\\n",
       "0  mrm8488/bert-tiny-finetuned-fake-news-detection  0.465214  0.474819   \n",
       "1                 jy46604790/Fake-News-Bert-Detect  0.652319  0.983162   \n",
       "2                  yasmine-11/distilbert_fake_news  0.484426  0.485065   \n",
       "\n",
       "     recall        f1  \n",
       "0    0.9576  0.634851  \n",
       "1  0.288782  0.446434  \n",
       "2  0.988176  0.650714  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "results.to_csv(\"./output/pre_trained_models.csv\")\n",
    "display(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56a57d93",
   "metadata": {},
   "source": [
    "### 7. Data Cleaning Alternative Strategies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "72c0275e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>fit_time</th>\n",
       "      <th>vectorizer</th>\n",
       "      <th>accuracy_train</th>\n",
       "      <th>precision_train</th>\n",
       "      <th>recall_train</th>\n",
       "      <th>f1_train</th>\n",
       "      <th>accuracy_test</th>\n",
       "      <th>precision_test</th>\n",
       "      <th>recall_test</th>\n",
       "      <th>f1_test</th>\n",
       "      <th>name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>5.339275</td>\n",
       "      <td>CountVectorizer</td>\n",
       "      <td>0.998426</td>\n",
       "      <td>0.997220</td>\n",
       "      <td>0.999548</td>\n",
       "      <td>0.998383</td>\n",
       "      <td>0.952716</td>\n",
       "      <td>0.940290</td>\n",
       "      <td>0.963356</td>\n",
       "      <td>0.951683</td>\n",
       "      <td>less_cleaning</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>4.540784</td>\n",
       "      <td>CountVectorizer</td>\n",
       "      <td>0.998243</td>\n",
       "      <td>0.996845</td>\n",
       "      <td>0.999548</td>\n",
       "      <td>0.998195</td>\n",
       "      <td>0.952862</td>\n",
       "      <td>0.940828</td>\n",
       "      <td>0.963053</td>\n",
       "      <td>0.951811</td>\n",
       "      <td>clean_serie</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>5.126765</td>\n",
       "      <td>CountVectorizer</td>\n",
       "      <td>0.998426</td>\n",
       "      <td>0.997220</td>\n",
       "      <td>0.999548</td>\n",
       "      <td>0.998383</td>\n",
       "      <td>0.952569</td>\n",
       "      <td>0.939752</td>\n",
       "      <td>0.963658</td>\n",
       "      <td>0.951555</td>\n",
       "      <td>no_cleanning</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                model  fit_time       vectorizer  accuracy_train  \\\n",
       "0  LogisticRegression  5.339275  CountVectorizer        0.998426   \n",
       "1  LogisticRegression  4.540784  CountVectorizer        0.998243   \n",
       "2  LogisticRegression  5.126765  CountVectorizer        0.998426   \n",
       "\n",
       "   precision_train  recall_train  f1_train  accuracy_test  precision_test  \\\n",
       "0         0.997220      0.999548  0.998383       0.952716        0.940290   \n",
       "1         0.996845      0.999548  0.998195       0.952862        0.940828   \n",
       "2         0.997220      0.999548  0.998383       0.952569        0.939752   \n",
       "\n",
       "   recall_test   f1_test           name  \n",
       "0     0.963356  0.951683  less_cleaning  \n",
       "1     0.963053  0.951811    clean_serie  \n",
       "2     0.963658  0.951555   no_cleanning  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def less_cleaning(serie):\n",
    "    # Replace apostrofo\n",
    "    serie = serie.replace(r\",s\", \"'s\", regex=True, inplace=False)\n",
    "    # Remove SOME characters, keeping * ' - ( ) \n",
    "    serie = serie.replace(r\"[^a-zA-Z0-9*'\\-().]\", \" \", regex=True, inplace=False)\n",
    "    # Remove multiple empty spaces\n",
    "    serie = serie.replace(r\"\\s{2,}\", \" \", regex=True, inplace=False)\n",
    "    # Make all string lowercase\n",
    "    serie = serie.str.lower()\n",
    "    return serie\n",
    "\n",
    "X2_train, X2_test, y2_train, y2_test = sklearn.model_selection.train_test_split(train_df[\"corpus\"], train_df[\"label\"], test_size=.2, random_state=seed)\n",
    "\n",
    "results=[]\n",
    "result = evaluate_model(model = sklearn.linear_model.LogisticRegression(random_state=seed), \n",
    "                        vectorizer = sklearn.feature_extraction.text.CountVectorizer(ngram_range = (1, 2)),\n",
    "                        X_train    = less_cleaning(X2_train), \n",
    "                        y_train    = y2_train, \n",
    "                        X_test     = less_cleaning(X2_test), \n",
    "                        y_test     = y2_test)\n",
    "result[\"name\"] = \"less_cleaning\"\n",
    "results.append(result)\n",
    "\n",
    "result = evaluate_model(model      = sklearn.linear_model.LogisticRegression(random_state=seed), \n",
    "                        vectorizer = sklearn.feature_extraction.text.CountVectorizer(ngram_range = (1, 2)),\n",
    "                        X_train    = clean_serie(X2_train), \n",
    "                        y_train    = y2_train, \n",
    "                        X_test     = clean_serie(X2_test), \n",
    "                        y_test     = y2_test)\n",
    "result[\"name\"] = \"clean_serie\"\n",
    "results.append(result)\n",
    "\n",
    "result = evaluate_model(model      = sklearn.linear_model.LogisticRegression(random_state=seed), \n",
    "                        vectorizer = sklearn.feature_extraction.text.CountVectorizer(ngram_range = (1, 2)),\n",
    "                        X_train    = X2_train, \n",
    "                        y_train    = y2_train, \n",
    "                        X_test     = X2_test, \n",
    "                        y_test     = y2_test)\n",
    "result[\"name\"] = \"no_cleanning\"\n",
    "results.append(result)\n",
    "\n",
    "results = pd.DataFrame(results)\n",
    "results.to_csv(\"./output/alternative_data_cleanning.csv\")\n",
    "display(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "602ed7cc",
   "metadata": {},
   "source": [
    "## 8. Final Model Application"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33d8f21d",
   "metadata": {},
   "source": [
    "### 8.1. Best Model Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "cde2a3c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accuracy_train</th>\n",
       "      <th>precision_train</th>\n",
       "      <th>recall_train</th>\n",
       "      <th>f1_train</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.998536</td>\n",
       "      <td>0.997352</td>\n",
       "      <td>0.999638</td>\n",
       "      <td>0.998494</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   accuracy_train  precision_train  recall_train  f1_train\n",
       "0        0.998536         0.997352      0.999638  0.998494"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Best Model\n",
    "bmodel = sklearn.linear_model.LogisticRegression(random_state=seed)\n",
    "bvect  = sklearn.feature_extraction.text.CountVectorizer(ngram_range = (1, 2))\n",
    "\n",
    "# Train the model with all data\n",
    "bm_train_ds = bvect.fit_transform(clean_serie(train_df[\"corpus\"]))\n",
    "\n",
    "# Fit the model\n",
    "bmodel.fit(bm_train_ds, train_df[\"label\"])\n",
    "\n",
    "bmodel_train_predict = bmodel.predict(bm_train_ds)\n",
    "\n",
    "result = get_classifier_metrics(train_df[\"label\"], bmodel_train_predict , sub_name=\"_train\")\n",
    "display(pd.DataFrame.from_dict(result, orient='index').T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "3eb0f162",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_df = pd.read_csv(\"./dataset/testing_data.csv\", sep=\"\\t\", header=None)\n",
    "val_df.columns = [\"label\", \"corpus\"]\n",
    "\n",
    "X_val = clean_serie(val_df[\"corpus\"])\n",
    "val_ds = bvect.transform(X_val)\n",
    "\n",
    "val_predict = bmodel.predict(val_ds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eea60875",
   "metadata": {},
   "source": [
    "### 8.2. Save the results in a new file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "3440715e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>corpus</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>copycat muslim terrorist arrested with assault...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>wow! chicago protester caught on camera admits...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>germany's fdp look to fill schaeuble's big shoes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>mi school sends welcome back packet warning ki...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>u.n. seeks 'massive' aid boost amid rohingya '...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9979</th>\n",
       "      <td>0</td>\n",
       "      <td>boom! fox news leftist chris wallace attempts ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9980</th>\n",
       "      <td>0</td>\n",
       "      <td>here it is: list of democrat hypocrites who vo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9981</th>\n",
       "      <td>1</td>\n",
       "      <td>new fires ravage rohingya villages in northwes...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9982</th>\n",
       "      <td>0</td>\n",
       "      <td>meals on wheels shuts the lyin‚ lefties up wit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9983</th>\n",
       "      <td>0</td>\n",
       "      <td>brilliant! tucker carlson and ayaan hirsi ali ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9984 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      label                                             corpus\n",
       "0         0  copycat muslim terrorist arrested with assault...\n",
       "1         0  wow! chicago protester caught on camera admits...\n",
       "2         1   germany's fdp look to fill schaeuble's big shoes\n",
       "3         0  mi school sends welcome back packet warning ki...\n",
       "4         1  u.n. seeks 'massive' aid boost amid rohingya '...\n",
       "...     ...                                                ...\n",
       "9979      0  boom! fox news leftist chris wallace attempts ...\n",
       "9980      0  here it is: list of democrat hypocrites who vo...\n",
       "9981      1  new fires ravage rohingya villages in northwes...\n",
       "9982      0  meals on wheels shuts the lyin‚ lefties up wit...\n",
       "9983      0  brilliant! tucker carlson and ayaan hirsi ali ...\n",
       "\n",
       "[9984 rows x 2 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "val_df[\"label\"] = pd.Series(val_predict)\n",
    "display(val_df)\n",
    "val_df.to_csv(\"./output/testing_data.csv\", sep=\"\\t\", header=False, index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nltk2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
